{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89223f98",
   "metadata": {},
   "source": [
    "### Importing useful libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f77ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# For example, here's several helpful packages to load in\n",
    "import numpy as np   # linear algebra\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8220d",
   "metadata": {},
   "source": [
    "### Loading the dataset \n",
    "#### For implementation we will be using house prediction dataset . The dataset can be found [here](https://github.com/vrinda01go/Hellofoss/blob/main/Room_price_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"house_price_data.csv\")  #import text file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af08f245",
   "metadata": {},
   "source": [
    "# Visualizing and Cleaning the data\n",
    "\n",
    "We will now be removing the nan values and identical values from the dataset\n",
    "\n",
    "For seeing if there are nan values in the dataset we will use the isna() function and then to remove them we will use the dropna() function. We will need to set additional parameters like rows and columns in the dropna function depending on the number of nan values present for each column\n",
    "\n",
    "Using the sum() function with isna() function we can get to know the number of missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef03c3",
   "metadata": {},
   "source": [
    "After this we will proceed to remove the nan values \n",
    "\n",
    "Since there are not many nan values in the column 'Price' as compared to the number of rows we will remove the rows which have nan values. \n",
    "\n",
    "Reseting the index after removing the nan values and dropping the old index will also be important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e4503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40784889",
   "metadata": {},
   "source": [
    "Now we can use the drop_duplicate function to remove the duplicate values\n",
    "\n",
    "This function has a parameter calle 'keep' where we specifiy to drop and which value to keep\n",
    "\n",
    "For this excercise we will keep the first values and drop the rest of the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a007a33f",
   "metadata": {},
   "source": [
    "For visualizing the data we will first start with looking at the distribution of different columns to see if there are enough number for each category in every column and dropping them if the data is biased for one category more than the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "for column in columns:\n",
    "    #fill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9811a731",
   "metadata": {},
   "source": [
    "We can clearly notice that for the Occupancy column the (occupancy) = 4 has a really low set of data points as compared to others. Hence we can proceed in dropping those rows where the occupancy is 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825783c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = #fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c64310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f333875b",
   "metadata": {},
   "source": [
    "We will now write the columns between categorical and numerical\n",
    "\n",
    "categorical = Hostel No, occupancy, floor\n",
    "\n",
    "Numerical = price, occupancy, roomsize, floor, hostel No.\n",
    "\n",
    "Remember that we can treat Hostel Number and occupancy as numerical or categorical. For this notebook we will treat them as categorical for data visualization and numerical for the regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f34ca6a",
   "metadata": {},
   "source": [
    "We will also plot the scatter plots and the correlation map to analyse the relation ships between different numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a3ab6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical = ['Hostel No.', 'Occupancy', 'Floor']\n",
    "numerical = [ 'Price', 'Room Size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column1 in numerical:\n",
    "    for column2 in numerical:\n",
    "        if(column1 != column2):\n",
    "            #fill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b89a8",
   "metadata": {},
   "source": [
    "We can notice that there are no linear relation present between the numerical columns. Hence no need to drop anything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f95fa",
   "metadata": {},
   "source": [
    "Now we will plot box plots of categorical and numerical columns to get more information about the number of outliers and the distrubtion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in categorical:\n",
    "    for n in numerical:\n",
    "        #fill\n",
    "        # we can use the boxplot function of pandas (refer to the documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d69fd",
   "metadata": {},
   "source": [
    "Now that we have analysed our data we can proceed to normalixing our data and regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8c6ba",
   "metadata": {},
   "source": [
    "### Importing useful libraries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffac537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# For example, here's several helpful packages to load in\n",
    "import numpy as np   # linear algebra\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd7e4e",
   "metadata": {},
   "source": [
    "### Loading the dataset \n",
    "#### For implementation we will be using house prediction dataset . The dataset can be found [here](https://github.com/vrinda01go/Hellofoss/blob/main/Insti_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df, dtype=float)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a5a3a",
   "metadata": {},
   "source": [
    "#### Since our dataset has four features i.e Hostel No. , Occupancy, Room Size and Floor ,our hypothesis function becomes\n",
    "### hθ(x) = θ0 + θ1x1 + θ2x2 +θ3x3 + θ4x4\n",
    "#### where x1 ,x2,x3 and x4 are the two features (i.e. size of house and number of rooms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fdf0fe",
   "metadata": {},
   "source": [
    "### So Your task is to define hypothesis function having 4 features and a corresponding cost function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc5643",
   "metadata": {},
   "outputs": [],
   "source": [
    " # define and complete hypothesis function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and complete cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178eb11f",
   "metadata": {},
   "source": [
    "### Gradient Descent \n",
    "#### So we have our hypothesis function and we have a way of measuring how well it fits into the data. Now we need to estimate the parameters in the hypothesis function. That's where gradient descent comes in.\n",
    "### Your next task is to define gradient descent function having some specific value of learning rate and number of epochs.\n",
    "#### Note that learning rate should be neither very high nor very low .Why?\n",
    "#### Check out exact reason [here](https://towardsdatascience.com/understanding-learning-rates-and-how-it-improves-performance-in-deep-learning-d0d4059c1c10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and complete Gradient Descent function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e407a",
   "metadata": {},
   "source": [
    "### Now we want to visualize how our cost function varies with number of epochs .So your next task is to plot graph of updated costs vs number of epochs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f6ebf",
   "metadata": {},
   "source": [
    "#### After plotting above graph you will notice that your cost function decreases with epochs.\n",
    "#### Perfect! This is all what we wanted to seek by doing linear regression. \n",
    "\n",
    "#### Now it's time to test our model on some test data. \n",
    "\n",
    "#### For this you will define a test function that will take as input Hostel No. , Occupancy, Room Size , Floor and the final theta vector that was returned by our linear regression model and will give us the price of the house. Compute it for any set of features given and final value of theta as given by gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c522bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and complete test function that will take required inputs .This function should return price of Room "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947f35b1",
   "metadata": {},
   "source": [
    "#### Now since we have defined all required functions , we can call functions one by one and get our final results .\n",
    "#### Your final task is to use all functions defined above and predict the price of room for some input combinations to check how well your model works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e54ef5",
   "metadata": {},
   "source": [
    "#### You can try playing with different values of alpha and epochs and see which combination gives most accurate results but do lookout for overfitting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc631fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
